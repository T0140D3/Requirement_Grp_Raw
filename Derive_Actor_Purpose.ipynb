{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250e3ded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991e79b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0e2c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "381b8ffa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d751806c",
   "metadata": {},
   "source": [
    "## Content Enrichment Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1557a27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def build_chunk_prompt(requirements_chunk):\n",
    "    requirements_text = json.dumps(requirements_chunk, indent=2)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "\n",
    "You are an expert business analyst specializing in requirement analysis and natural language processing. Your task is to convert technical requirements into clear, understandable natural language descriptions.\n",
    "You are given multiple requirements in JSON format:\n",
    "{requirements_text}\n",
    "INSTRUCTIONS:\n",
    "1. Read and analyze the provided requirement content thoroughly\n",
    "2. Identify the core business intent and functionality described\n",
    "3. Convert any technical variable names, method names, or system identifiers into human-readable terms by understanding their semantic meaning\n",
    "4. Transform camelCase, PascalCase, or snake_case variables into natural language (e.g., \"HornActivationRequest\" → \"horn activation request\", \"getUserProfile\" → \"get user profile\", \"payment_status_check\" → \"payment status check\")\n",
    "6. Remove all technical jargon, code syntax, and variable references\n",
    "7. Use active voice and clear, concise language\n",
    "8. Ensure the output is understandable to non-technical stakeholders\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "Return your response as a JSON object with the following structure:\n",
    "{{\n",
    "  \"req_id\":<\"requirement_id>\",\n",
    "  \"original_content\": \"<The exact original requirement text>\",\n",
    "  \"natural_language_description\": \"<Clear, jargon-free description of what the requirement means in business terms>\"\n",
    "}}\n",
    "\n",
    "EXAMPLES:\n",
    "Input: \"When HornActivationRequest is triggered and vehicleSpeed > 0, execute soundAlert() function\"\n",
    "Output: {{\n",
    "  \"original_content\": \"When HornActivationRequest is triggered and vehicleSpeed > 0, execute soundAlert() function\",\n",
    "  \"natural_language_description\": \"When a horn activation request is made while the vehicle is moving, the system should produce a sound alert\",\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facde99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ollama\n",
    "\n",
    "def load_requirements(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def chunk_requirements(reqs, chunk_size=2):\n",
    "    for i in range(0, len(reqs), chunk_size):\n",
    "        yield reqs[i:i+chunk_size]\n",
    "\n",
    "def call_llm_model(chunk):\n",
    "    prmt=build_chunk_prompt(chunk)\n",
    "    response = ollama.chat(\n",
    "        model=\"mistral\",  # Use any installed model like llama2, etc.\n",
    "        messages=[{\"role\": \"user\", \"content\": prmt}],options={\"temperature\": 0}\n",
    "    )\n",
    "    sponse_text = response['message']['content']\n",
    "    return sponse_text\n",
    "\n",
    "def main(input_file, output_file, chunk_size=2):\n",
    "    requirements = load_requirements(input_file)\n",
    "    all_results = []\n",
    "\n",
    "    for chunk in chunk_requirements(requirements, chunk_size):\n",
    "        # Call your LLM model here with the chunk\n",
    "        result = call_llm_model(chunk)\n",
    "        all_results.append(result)\n",
    "    return all_results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_json_file = \"requirements.json\"  # your input file\n",
    "    output_json_file = \"processed_requirements.json\"  # final output file\n",
    "    y=main(input_json_file, output_json_file, chunk_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e46a5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"req_ids.json\", \"w\") as f:\n",
    "    json.dump(y, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2a7b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "scenario_json1=[]\n",
    "for i in y:\n",
    "    match = re.search(r\"```json\\n(.*?)\\n```\", i, re.DOTALL)\n",
    "    if match:\n",
    "        json_str = match.group(1)\n",
    "        scenario_json = json.loads(json_str)\n",
    "    else:\n",
    "        scenario_json = json.loads(i)\n",
    "    scenario_json1.extend(scenario_json)\n",
    "\n",
    "with open(\"actor_pupose1.json\", \"w\") as json_file:\n",
    "    json.dump(scenario_json1, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7218887",
   "metadata": {},
   "source": [
    "###Extract Noun verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15209d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt(requirements_chunk):\n",
    "  \n",
    "  requirements_text = json.dumps(requirements_chunk, indent=2)\n",
    "  prompt = f\"\"\"\n",
    "You are a requirements analysis expert. Your task is to extract actors, targets, verbs, and nouns from the given requirement content.\n",
    "\n",
    "You are given multiple requirements in JSON format:\n",
    "{requirements_text}\n",
    "\n",
    "STRICT RULES:\n",
    "1. Analyze ONLY the provided requirement content.\n",
    "2. Do NOT add any external information or assumptions.\n",
    "3. Do NOT include variable names, method names, or technical identifiers in any category.\n",
    "4. Convert technical terms to natural language concepts only.\n",
    "5. Extract only meaningful business entities and actions.\n",
    "6. Output must be in strict JSON format.\n",
    "7. Use lowercase for consistency.\n",
    "\n",
    "DEFINITIONS:\n",
    "- actors: who performs the action (users, systems, roles that initiate or perform actions)\n",
    "- targets: what is being acted upon (objects, systems, data that receive actions)\n",
    "- verbs: business actions or operations (what is being done)\n",
    "- nouns: business entities or concepts (things involved in the process)\n",
    "\n",
    "EXTRACTION GUIDELINES:\n",
    "- Convert \"UserAuthenticationService\" → actor: \"authentication service\", noun: \"authentication\"\n",
    "- Convert \"validateCredentials()\" → verb: \"validate\", noun: \"credentials\"\n",
    "- Convert \"HornActivationRequest\" → actor: \"driver/user\", target: \"horn system\", verb: \"activate\", noun: \"horn\"\n",
    "- Convert \"updateAccountBalance\" → verb: \"update\", noun: \"account balance\"\n",
    "\n",
    "FORBIDDEN:\n",
    "- Do not include variable names, class names, method names, technical identifiers\n",
    "- Do not include programming syntax, camelCase terms, function calls\n",
    "- Do not add information not present in the requirement\n",
    "\n",
    "OUTPUT FORMAT (strict JSON, arrays must use brackets []):\n",
    "\n",
    "  {{\n",
    "    \"req_id\": \"<requirement_id>\",\n",
    "    \"natural_language_description\": \"<natural_language_description>\",\n",
    "    \"actors\": [\"actor1\", \"actor2\"],\n",
    "    \"targets\": [\"target1\", \"target2\"],\n",
    "    \"verbs\": [\"verb1\", \"verb2\"],\n",
    "    \"nouns\": [\"noun1\", \"noun2\"]\n",
    "  }}\n",
    "\n",
    "EXAMPLE:\n",
    "\n",
    "Input: \"When HornActivationRequest is triggered and vehicleSpeed > 0, execute soundAlert() function\"\n",
    "\n",
    "Output:\n",
    "  {{\n",
    "    \"req_id\": \"REQ-001\",\n",
    "    \"natural_language_description\": \"When horn activation request is triggered and vehicle speed is greater than zero, execute the sound alert\",\n",
    "    \"actors\": [\"driver\", \"system\"],\n",
    "    \"targets\": [\"horn\", \"alert system\"],\n",
    "    \"verbs\": [\"trigger\", \"activate\", \"execute\", \"alert\"],\n",
    "    \"nouns\": [\"horn\", \"vehicle\", \"speed\", \"sound\", \"alert\"]\n",
    "  }}\n",
    "\n",
    "\n",
    "NOW GENERATE STRICTLY JSON OUTPUT FOR ALL REQUIREMENTS ABOVE. DO NOT ADD ANYTHING ELSE.\n",
    "\"\"\"\n",
    "\n",
    "  return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb297a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ollama\n",
    "\n",
    "def load_requirements(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def chunk_requirements(reqs, chunk_size=2):\n",
    "    for i in range(0, len(reqs), chunk_size):\n",
    "        yield reqs[i:i+chunk_size]\n",
    "\n",
    "def call_llm_model(chunk):\n",
    "    prmt=prompt(chunk)\n",
    "    response = ollama.chat(\n",
    "        model=\"mistral\",  # Use any installed model like llama2, etc.\n",
    "        messages=[{\"role\": \"user\", \"content\": prmt}],options={\"temperature\": 0}\n",
    "    )\n",
    "    sponse_text = response['message']['content']\n",
    "    return sponse_text\n",
    "\n",
    "def main(input_file, output_file, chunk_size=2):\n",
    "    requirements = load_requirements(input_file)\n",
    "    all_results = []\n",
    "\n",
    "    for chunk in chunk_requirements(requirements, chunk_size):\n",
    "        # Call your LLM model here with the chunk\n",
    "        result = call_llm_model(chunk)\n",
    "        all_results.append(result)\n",
    "    return all_results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_json_file = \"actor_pupose.json\"  # your input file\n",
    "    output_json_file = \"processed_requirements.json\"  # final output file\n",
    "    y=main(input_json_file, output_json_file, chunk_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551b64a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a47665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "scenario_json1=[]\n",
    "for i in y:\n",
    "    match = re.search(r\"```json\\n(.*?)\\n```\", i, re.DOTALL)\n",
    "    if match:\n",
    "        json_str = match.group(1)\n",
    "        scenario_json = json.loads(json_str)\n",
    "    else:\n",
    "        scenario_json = json.loads(i)\n",
    "    scenario_json1.extend(scenario_json)\n",
    "\n",
    "with open(\"actor_target_nouns_verbs1.json\", \"w\") as json_file:\n",
    "    json.dump(scenario_json1, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd4edf1",
   "metadata": {},
   "source": [
    "###Inputs and outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d486e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prmpt_input(requirements_chunk):\n",
    "  requirements_text = json.dumps(requirements_chunk, indent=2)\n",
    "  prompt=f\"\"\"You are an expert requirements analyst. Your task is to carefully analyze the given requirement content and extract ALL inputs and outputs mentioned or implied in the requirement.\n",
    "You are given multiple requirements in JSON format:\n",
    "{requirements_text}\n",
    "STRICT INSTRUCTIONS:\n",
    "1. Read the requirement original content CAREFULLY and COMPLETELY\n",
    "2. Extract ONLY inputs and outputs that are explicitly mentioned or directly implied in the provided content\n",
    "3. Do NOT add any external information, assumptions, or related requirements\n",
    "4. Process ONLY the given requirement ID and its content\n",
    "7. Output must be in strict JSON format\n",
    "\n",
    "DEFINITIONS:\n",
    "- INPUTS: Any data, conditions, parameters, or triggers that go INTO the system/process described in the requirement\n",
    "- OUTPUTS: Any data, results, actions, responses, or effects that come OUT OF the system/process described in the requirement\n",
    "\n",
    "EXTRACTION RULES:\n",
    "- If requirement mentions \"when X happens\" → X is an input\n",
    "- If requirement mentions \"system receives Y\" → Y is an input  \n",
    "- If requirement mentions \"check Z condition\" → Z is an input\n",
    "- If requirement mentions \"system produces A\" → A is an output\n",
    "- If requirement mentions \"display B\" → B is an output\n",
    "- If requirement mentions \"update C\" → C is an output\n",
    "- If requirement mentions \"send notification\" → \"notification\" is an output\n",
    "\n",
    "OUTPUT FORMAT (strict JSON):\n",
    "{{\n",
    "  \"req_id\": \"<the provided requirement ID>\",\n",
    "  \"inputs\": [\"list of all inputs found in the requirement\"],\n",
    "  \"outputs\": [\"list of all outputs found in the requirement\"]\n",
    "}}\n",
    "NOW GENERATE STRICTLY JSON OUTPUT FOR ALL REQUIREMENTS ABOVE. DO NOT ADD ANYTHING ELSE.\n",
    "\"\"\"\n",
    "  return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f271598d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ollama\n",
    "\n",
    "def load_requirements(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def chunk_requirements(reqs, chunk_size=2):\n",
    "    for i in range(0, len(reqs), chunk_size):\n",
    "        yield reqs[i:i+chunk_size]\n",
    "\n",
    "def call_llm_model(chunk):\n",
    "    prmt=build_prmpt_input(chunk)\n",
    "    response = ollama.chat(\n",
    "        model=\"mistral\",  # Use any installed model like llama2, etc.\n",
    "        messages=[{\"role\": \"user\", \"content\": prmt}],options={\"temperature\": 0}\n",
    "    )\n",
    "    sponse_text = response['message']['content']\n",
    "    return sponse_text\n",
    "\n",
    "def main(input_file, output_file, chunk_size=2):\n",
    "    requirements = load_requirements(input_file)\n",
    "    all_results = []\n",
    "\n",
    "    for chunk in chunk_requirements(requirements, chunk_size):\n",
    "        # Call your LLM model here with the chunk\n",
    "        result = call_llm_model(chunk)\n",
    "        all_results.append(result)\n",
    "    return all_results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_json_file = \"actor_pupose1.json\"  # your input file\n",
    "    output_json_file = \"processed_requirements.json\"  # final output file\n",
    "    y=main(input_json_file, output_json_file, chunk_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cc2ae50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "scenario_json1=[]\n",
    "for i in y:\n",
    "    match = re.search(r\"```json\\n(.*?)\\n```\", i, re.DOTALL)\n",
    "    if match:\n",
    "        json_str = match.group(1)\n",
    "        scenario_json = json.loads(json_str)\n",
    "    else:\n",
    "        scenario_json = json.loads(i)\n",
    "    scenario_json1.extend(scenario_json)\n",
    "\n",
    "with open(\"Inputs_outputs.json\", \"w\") as json_file:\n",
    "    json.dump(scenario_json1, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546805f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Merging_Content_inputs_ouputs_verbs_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b78acd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load JSON files\n",
    "with open(\"actor_target_nouns_verbs1.json\", \"r\") as f1:\n",
    "    semantic_data = json.load(f1)  # [{\"req_id\": ..., \"inputs\": [...], \"outputs\": [...]}]\n",
    "\n",
    "with open(\"Inputs_outputs.json\", \"r\") as f2:\n",
    "    io_data = json.load(f2)  # [{\"req_id\": ..., \"actors\": [...], \"targets\": [...], \"verbs\": [...], \"nouns\": [...]}]\n",
    "\n",
    "for i in io_data:\n",
    "    temp = i['req_id'].split(\" \")\n",
    "\n",
    "    if len(temp) > 2 and temp[2].strip():  # check if third part exists and not empty\n",
    "        i['req_id'] = temp[0] + \" \" + temp[2]\n",
    "        t = temp[2]\n",
    "    else:\n",
    "        if len(temp) > 1:\n",
    "            i['req_id'] = temp[0] + \" \" + temp[1]\n",
    "        else:\n",
    "            i['req_id'] = temp[0]  # fallback if only one part exists\n",
    "   \n",
    "for i in semantic_data:\n",
    "    temp = i['req_id'].split(\" \")\n",
    "\n",
    "    if len(temp) > 2 and temp[2].strip():  # check if third part exists and not empty\n",
    "        i['req_id'] = temp[0] + \" \" + temp[2]\n",
    "        t = temp[2]\n",
    "    else:\n",
    "        if len(temp) > 1:\n",
    "            i['req_id'] = temp[0] + \" \" + temp[1]\n",
    "        else:\n",
    "            i['req_id'] = temp[0]\n",
    "\n",
    "\n",
    "\n",
    "# Create a lookup dict for semantic data\n",
    "semantic_dict = {item[\"req_id\"]: item for item in semantic_data}\n",
    "\n",
    "# Merge entries\n",
    "merged_data = []\n",
    "for io_item in io_data:\n",
    "    req_id = io_item[\"req_id\"]\n",
    "    merged_item = {\n",
    "        \"req_id\": req_id,\n",
    "        \"inputs\": io_item.get(\"inputs\", []),\n",
    "        \"outputs\": io_item.get(\"outputs\", [])\n",
    "    }\n",
    "\n",
    "    # Add semantic info if exists\n",
    "    semantic_item = semantic_dict.get(req_id, {})\n",
    "    merged_item.update({\"Content\":semantic_item.get(\"natural_language_description\"),\n",
    "        \"actors\": list(set(semantic_item.get(\"actors\", []))),\n",
    "        \"targets\": list(set(semantic_item.get(\"targets\", []))),\n",
    "        \"verbs\": list(set(semantic_item.get(\"verbs\", []))),\n",
    "        \"nouns\": list(set(semantic_item.get(\"nouns\", [])))\n",
    "    })\n",
    "\n",
    "    merged_data.append(merged_item)\n",
    "\n",
    "# Save merged JSON\n",
    "with open(\"merged_requirements.json\", \"w\") as fout:\n",
    "    json.dump(merged_data, fout, indent=2)\n",
    "\n",
    "# print(\"Merged JSON created successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
